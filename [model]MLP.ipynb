{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all necessary train and test data from the data preprocessing file\n",
    "%run ./Preprocess_keep_features_except_geo_2_3.ipynb\n",
    "%run ./Preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import common\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model using only geo_level_1_id and removed features, UNSAMPLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on train data: 66.84%\n",
      "Model accuracy on test data: 66.73%\n",
      "\n",
      "\n",
      "\t\tclassification_report on test data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.34      0.43      5041\n",
      "           2       0.67      0.81      0.74     29640\n",
      "           3       0.67      0.52      0.58     17440\n",
      "\n",
      "    accuracy                           0.67     52121\n",
      "   macro avg       0.64      0.56      0.58     52121\n",
      "weighted avg       0.66      0.67      0.66     52121\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 1713  3241    87]\n",
      " [ 1164 24022  4454]\n",
      " [   51  8342  9047]]\n",
      "\n",
      "F1-Micro:  0.6673317856526161\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', max_iter=100, hidden_layer_sizes=(90,10), activation='tanh', early_stopping=True)\n",
    "clf.fit(train_x, train_y)\n",
    "y_pred = clf.predict(test_x)\n",
    "print(\"Model accuracy on train data: {:.2f}%\".format(clf.score(train_x, train_y)*100))\n",
    "print(\"Model accuracy on test data: {:.2f}%\".format(clf.score(test_x, test_y)*100))\n",
    "print(\"\\n\\n\\t\\tclassification_report on test data\\n\")\n",
    "print(classification_report(test_y, y_pred))\n",
    "print(\"Confusion matrix\\n\")\n",
    "print(confusion_matrix(test_y, y_pred))\n",
    "print()\n",
    "print(\"F1-Micro: \", f1_score(test_y, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model using only geo_level_1_id and removed features, OVERSAMPLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on train data: 66.50%\n",
      "Model accuracy on test data: 59.32%\n",
      "\n",
      "\n",
      "\t\tclassification_report on test data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.79      0.49      5005\n",
      "           2       0.74      0.50      0.59     29641\n",
      "           3       0.59      0.70      0.64     17475\n",
      "\n",
      "    accuracy                           0.59     52121\n",
      "   macro avg       0.56      0.66      0.57     52121\n",
      "weighted avg       0.65      0.59      0.60     52121\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 3966   898   141]\n",
      " [ 6469 14748  8424]\n",
      " [  888  4384 12203]]\n",
      "\n",
      "F1-Micro:  0.5931774140941272\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', max_iter=100, hidden_layer_sizes=(90,10), activation='tanh', early_stopping=True)\n",
    "clf.fit(train_x_over, train_y_over)\n",
    "y_pred_over = clf.predict(test_x_over)\n",
    "print(\"Model accuracy on train data: {:.2f}%\".format(clf.score(train_x_over, train_y_over)*100))\n",
    "print(\"Model accuracy on test data: {:.2f}%\".format(clf.score(test_x_over, test_y_over)*100))\n",
    "\n",
    "y_pred = clf.predict(test_x_over)\n",
    "print(\"\\n\\n\\t\\tclassification_report on test data\\n\")\n",
    "print(classification_report(test_y_over, y_pred))\n",
    "print(\"Confusion matrix\\n\")\n",
    "print(confusion_matrix(test_y_over, y_pred))\n",
    "print()\n",
    "print(\"F1-Micro: \", f1_score(test_y_over, y_pred, average='micro'))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model using only geo_level_1_id and all features, UNSAMPLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on train data: 68.13%\n",
      "Model accuracy on test data: 67.64%\n",
      "\n",
      "\n",
      "\t\tclassification_report on test data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.45      5031\n",
      "           2       0.68      0.83      0.75     29730\n",
      "           3       0.68      0.51      0.58     17359\n",
      "\n",
      "    accuracy                           0.68     52120\n",
      "   macro avg       0.66      0.56      0.59     52120\n",
      "weighted avg       0.67      0.68      0.66     52120\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 1752  3208    71]\n",
      " [ 1012 24638  4080]\n",
      " [   67  8430  8862]]\n",
      "\n",
      "F1-Micro:  0.6763622409823484\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', max_iter=100, hidden_layer_sizes=(90,10), activation='tanh', early_stopping=True)\n",
    "clf.fit(train_x_keep, train_y_keep)\n",
    "y_pred_over = clf.predict(test_x_keep)\n",
    "print(\"Model accuracy on train data: {:.2f}%\".format(clf.score(train_x_keep, train_y_keep)*100))\n",
    "print(\"Model accuracy on test data: {:.2f}%\".format(clf.score(test_x_keep, test_y_keep)*100))\n",
    "\n",
    "y_pred = clf.predict(test_x_keep)\n",
    "print(\"\\n\\n\\t\\tclassification_report on test data\\n\")\n",
    "print(classification_report(test_y_keep, y_pred))\n",
    "print(\"Confusion matrix\\n\")\n",
    "print(confusion_matrix(test_y_keep, y_pred))\n",
    "print()\n",
    "print(\"F1-Micro: \", f1_score(test_y_keep, y_pred, average='micro'))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "<p> The baseline model using only geo_level_1_id and all features without unsampled data is the best model among the three. We will optimise this model by selecting the hyperparameters.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising the MLPClassifier\n",
    "### Using GridSearch to find the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Find the best hidden layer sizes, number of hidden layers, and alpha.</p>\n",
    "<p>As it takes a long time to train the models for the GridSearch, the cross-validation is done 2-fold only. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with all the features and only one-hot encoded geo_level_1_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.01\n",
      "Best Layer: (96, 40, 20, 10, 5)\n",
      "Model accuracy on train data: 68.11%\n",
      "Model accuracy on test data: 68.09%\n",
      "\n",
      "\n",
      "\t\tclassification_report on test data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.38      0.47      4982\n",
      "           2       0.70      0.79      0.74     29839\n",
      "           3       0.66      0.58      0.62     17300\n",
      "\n",
      "    accuracy                           0.68     52121\n",
      "   macro avg       0.65      0.58      0.61     52121\n",
      "weighted avg       0.68      0.68      0.67     52121\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 1917  2982    83]\n",
      " [ 1220 23525  5094]\n",
      " [   79  7173 10048]]\n",
      "\n",
      "F1-Micro:  0.6809155618656587\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "layer = [(96,40), (96,20), (48,25), (96,40,40), (96,40,20), (48,20,10), \\\n",
    "        (96,40,20,10), (96,40,20,10,5), (40,20,20), (20,20,20)]\n",
    "\n",
    "hyperparameters = dict(alpha= 10**(np.arange(-6,2,1.0)), hidden_layer_sizes=layer)\n",
    "mlp = MLPClassifier(solver='sgd', max_iter=100, activation='tanh', early_stopping=True)\n",
    "clf = GridSearchCV(mlp, hyperparameters, cv=2, scoring = 'f1_micro')\n",
    "best_model = clf.fit(train_x_keep,train_y_keep)\n",
    "print('Best Alpha:', best_model.best_estimator_.get_params()['alpha'])\n",
    "print('Best Layer:', best_model.best_estimator_.get_params()['hidden_layer_sizes'])\n",
    "print(\"Model accuracy on train data: {:.2f}%\".format(best_model.score(train_x_keep, train_y_keep)*100))\n",
    "print(\"Model accuracy on test data: {:.2f}%\".format(best_model.score(test_x_keep, test_y_keep)*100))\n",
    "\n",
    "y_pred = best_model.predict(test_x_keep)\n",
    "print(\"\\n\\n\\t\\tclassification_report on test data\\n\")\n",
    "print(classification_report(test_y_keep, y_pred))\n",
    "print(\"Confusion matrix\\n\")\n",
    "print(confusion_matrix(test_y_keep, y_pred))\n",
    "print()\n",
    "print(\"F1-Micro: \", f1_score(test_y_keep, y_pred, average='micro'))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(96, 40, 20, 10, 5), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=5000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha= 0.01, hidden_layer_sizes= (96, 40, 20, 10, 5), max_iter=5000, activation='tanh')\n",
    "clf.fit(train_x_keep, train_y_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = clf.predict(test_values_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stores trained optimised model\n",
    "pickle.dump(clf, open('model/mlp.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'building_id': test_building_id, 'damage_grade': np.int64(test_pred)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Results:\n",
    "\n",
    "### Baseline, features removed, unsampled: 0.667\n",
    "### Baseline, features removed, oversampled: 0.593\n",
    "\n",
    "### Baseline, features not removed, unsampled: 0.676\n",
    "\n",
    "### Optimised, features not removed, unsampled: 0.681\n",
    "\n",
    "\n",
    "## Test Results: 0.689"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
