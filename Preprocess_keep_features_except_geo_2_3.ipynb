{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview\n",
    "# Step 0: Combine train set and comptition test set\n",
    "# Step 1: Drop geo_level_2_id and geo_level_3_id features\n",
    "# Step 2: Normalization\n",
    "# Step 3: One-hot encode the categorical features\n",
    "# Step 4: Separate train set and comptition test set\n",
    "#         Save and drop feature: building id\n",
    "# Step 5: Split the data into train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_keep = pd.read_csv('data/train_values.csv')\n",
    "label_keep = pd.read_csv('data/train_labels.csv')\n",
    "test_values_keep = pd.read_csv('data/test_values.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Combine train set and comptition test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_keep = data_keep.append(test_values_keep).set_index(keys = 'building_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Drop geo_level_2_id and geo_index_3_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['geo_level_3_id', 'geo_level_2_id']\n",
    "\n",
    "to_enc = ['geo_level_1_id', 'foundation_type', 'roof_type', 'ground_floor_type', 'other_floor_type',\\\n",
    "          'plan_configuration', 'legal_ownership_status', 'land_surface_condition', 'position']\n",
    "\n",
    "num_col = ['count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage', 'count_families']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_keep.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Min-max scale both datasets (Normalization)\n",
    "\n",
    "#### Purpose of Min-max scale: Reduce weight of numeric features(features with high magnitudes) in model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max scale the training data_keepsets\n",
    "#Min-max scale test_values\n",
    "full_data_keep[num_col] = full_data_keep[num_col].astype('float')\n",
    "scaler = MinMaxScaler()\n",
    "full_data_keep[num_col] = scaler.fit_transform(full_data_keep[num_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: One hot encode the categorical features and preserve building id from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: One hot encode the categorical features\n",
    "full_data_keep = pd.get_dummies(full_data_keep, prefix=to_enc, columns=to_enc, dtype='bool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Separate train set and comptition test set. Save and remove feature: building id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_building_id = data_keep['building_id']\n",
    "test_building_id = test_values_keep['building_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_keep = full_data_keep.loc[train_building_id]\n",
    "test_values_keep = full_data_keep.loc[test_building_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(full_data_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_keep.reset_index(drop=True, inplace=True)\n",
    "test_values_keep.reset_index(drop=True, inplace=True)\n",
    "\n",
    "label_keep = label_keep['damage_grade']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Split train dataset into train, test\n",
    "#### The test set is used to check how well the learning model generalises to data it has not seen before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose your test size=0.2\n",
    "#Split both oversampled and non-oversampled data\n",
    "\n",
    "train_x_keep, test_x_keep, train_y_keep, test_y_keep = train_test_split(data_keep, label_keep, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
