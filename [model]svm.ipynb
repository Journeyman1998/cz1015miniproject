{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstraction\n",
    "## 1. Test the effect of different data preprocesses\n",
    "Tested preprocess:\n",
    "- ### [No preprocess](#Test-Preprocess:-No-preprocess)\n",
    "\n",
    "- ### [Preprocess 1](#Test-Preprocess:-Preprocess-1)\n",
    " - Drop less relevent data\n",
    " - One hot encode catagorical data\n",
    " - Normalize numerical data\n",
    "\n",
    "- ### [Preprocess 2](#Test-Preprocess:-Preprocess-2)\n",
    " - The same to Preprocess 1, and\n",
    " - Oversampling train set\n",
    "\n",
    "- ### [Preprocess 3](#Test-Preprocess:-Preprocess-3)\n",
    " - Only drop geo_level_2_id and geo_level_3_id\n",
    " - The other operations are the same to Preprocess 1\n",
    "\n",
    "- ### [Preprocess 4](#Test-Preprocess:-Preprocess-4)\n",
    " - Drop only geo_level_3_id\n",
    " - The other operations are the same to Preprocess 1\n",
    "\n",
    "## 2. Test the effect of different hyperparameters\n",
    "Tested hyperparameters:\n",
    "- [Iteration number](#Test-Hyperparameter:-max_iter)\n",
    "- [C: punishment on wrong resoposes](#Test-Hyperparameter:-C:-punishment-on-wrong-resoposes)\n",
    "- [class_weight](#Test-Hyperparameter:-class_weight)\n",
    "\n",
    "## 3. Test the effeck of different kernel trick\n",
    "<b><em>Notes: each of the following model may take more than 3 hours for training</em></b><br>\n",
    "Tested kernel trick:\n",
    "- [RBF](#Kernel-Trick-Test:-RBF)\n",
    "- [Polynomial (3 degree)](#Kernel-Trick-Test:-3-Degree-Polynomial)\n",
    "- [Sigmoid](#Kernel-Trick-Test:-Sigmoid)\n",
    "\n",
    "## 4. [Predict on DrivenData Competition Test Set](#Prediction-on-DrivenData-Competition-Dataset)\n",
    "## 5. [Save the Optimal Model](#Save-the-Optimal-Model-to-Avoid-Training-Again)\n",
    "\n",
    "\n",
    "# Results\n",
    "- ## Preprocess Test\n",
    " - Raw data cannot be used to train SVM. SVM only accepts number while raw data contains string\n",
    " - Preprocess 1: On test set: Accuracy: 0.6620, F1 Score: 0.6428\n",
    " - Preprocess 2: On test set: Accuracy: 0.5559, F1 Score: 0.5570\n",
    " - Preprocess 3: On test set: Accuracy: 0.6655, F1 Score: 0.6470\n",
    " - Preprocess 4: Fail to rum due to memory error\n",
    "\n",
    "- ## Hyperparameter Test:\n",
    " - Iteration number<br>\n",
    "    No effect, because the sk-learn model will adjust the iteration number automatically\n",
    " - C: punishment on wrong resoposes<br>\n",
    "    The optimal value is around 0.1~1.0.<br>\n",
    "    When C < 0.1, the accuracy of prediction decreases.<br>\n",
    "    When C > 1.0, the the risk of overfitting increases.<br>\n",
    " - class_weight\n",
    "   - Uniform weight: On test set: Accuracy: 0.6620, F1 Score: 0.6428\n",
    "   - Balanced weight: On test set: Accuracy: 0.6391, F1 Score: 0.6413\n",
    "\n",
    "- ## Kernel Trick Test\n",
    " - RBF: On test set: Accuracy: 0.6783, F1 Score: 0.6669\n",
    " - Polynomial: On test set: Accuracy: 0.6749, F1 Score: 0.6648\n",
    " - Sigmoid: On test set: Accuracy: 0.5448, F1 Score: 0.5460\n",
    " \n",
    "- ###  Test result on DrivenData: f1 score 0.6768\n",
    "\n",
    "# Conclusions\n",
    "- The optimal SVM model:\n",
    " - No oversampling\n",
    " - Drop less relative features to save training time\n",
    " - Using default C value (C = 1)\n",
    " - Using uniform class weight\n",
    " - Using RBF kernel\n",
    "- About oversampling:\n",
    " - It will degrade the overall performance\n",
    " - It will increase the accuracy of prediction of minor class, that is damage_grade == 1.\n",
    " - It will decrease the accuracy of prediction of major class, that is damage_grade == 2.\n",
    "- About class_weight:\n",
    " - Uniform weight provides better overall performance\n",
    " - Balanced weight provides more even performance on predicting each class\n",
    "- Our hardware is not powerful enough, cannot train model with ~1500 dimension features and training each SVM with kernel trick takes at least 3 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions\n",
    "[Back to abstraction](#Abstraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to print several parameters calculated form a confusion matrix.\n",
    "def print_conf_paras(conf_mat):\n",
    "    print('Classification Accuracy\\t:', conf_mat.trace()/conf_mat.sum())\n",
    "    print()\n",
    "    micro_f1 = 0\n",
    "    macro_f1 = 0\n",
    "    for i in range(len(conf_mat)):\n",
    "        tp = conf_mat[i,i]/conf_mat[i].sum()\n",
    "        fp = (conf_mat[:,i].sum()-conf_mat[i,i])/(conf_mat.sum()-conf_mat[i].sum())\n",
    "        fn = (conf_mat[i].sum()-conf_mat[i,i])/conf_mat[i].sum()\n",
    "        precision = conf_mat[i,i]/conf_mat[:,i].sum()\n",
    "        f1 = 2*precision*tp/(precision+tp)\n",
    "        micro_f1 += f1 * conf_mat[i].sum()\n",
    "        macro_f1 += f1\n",
    "        print('  True Positive Rate for ', i, '\\t:', tp)\n",
    "        print('  False Positive Rate for', i, '\\t:', fp)\n",
    "        print('  False Negative Rate for', i, '\\t:', fn)\n",
    "        print('  Precision & Recall for ', i, '\\t:', precision, tp)\n",
    "        print('  F1 Score for', i, '           \\t:', f1)\n",
    "        print()\n",
    "    micro_f1 /= conf_mat.sum()\n",
    "    macro_f1 /= len(conf_mat)\n",
    "    print('Micro F1 Score          \\t:', micro_f1)\n",
    "    print('Macro F1 Score          \\t:', macro_f1)\n",
    "\n",
    "# This function is used to print accuracy and f1 score calculated form a confusion matrix.\n",
    "def print_conf_paras_simple(conf_mat):\n",
    "    print('Classification Accuracy\\t:', conf_mat.trace()/conf_mat.sum())\n",
    "    micro_f1 = 0\n",
    "    for i in range(len(conf_mat)):\n",
    "        recall = conf_mat[i,i]/conf_mat[i].sum()\n",
    "        precision = conf_mat[i,i]/conf_mat[:,i].sum()\n",
    "        f1 = 2*precision*recall/(precision+recall)\n",
    "        micro_f1 += f1 * conf_mat[i].sum()\n",
    "    micro_f1 /= conf_mat.sum()\n",
    "    print('Micro F1 Score          \\t:', micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to run a linear SVM on the given data set with given hyperparameters,\n",
    "# then it will test the SVM with train set and test set and print the test results.\n",
    "# If verbose == True, it will print lots of test details.\n",
    "# If verbose == False, it will only print classification accuracy and micro f1 score\n",
    "# It return the trained SVM\n",
    "def test_linear_svm_with(train_X, train_Y, test_X, test_Y, verbose=True, max_iter=5000, **args):\n",
    "    # Training\n",
    "    linear_svc = LinearSVC(dual=False, max_iter=max_iter, **args)\n",
    "    linear_svc.fit(train_X, train_Y)\n",
    "    test_svm(linear_svc, train_X, train_Y, test_X, test_Y, verbose)\n",
    "    \n",
    "    return linear_svc\n",
    "\n",
    "# This function is used to test the given SVM with given data set\n",
    "# If verbose == True, it will print lots of details.\n",
    "# If verbose == False, it will only print classification accuracy and micro f1 score\n",
    "def test_svm(svc, train_X, train_Y, test_X, test_Y, verbose=True):\n",
    "    # Test on train set\n",
    "    train_pred = svc.predict(train_X)\n",
    "    train_conf = confusion_matrix(train_Y, train_pred)\n",
    "    print('======= Test result on train set =======')\n",
    "    if verbose:\n",
    "        print_conf_paras(train_conf)\n",
    "    else:\n",
    "        print_conf_paras_simple(train_conf)\n",
    "    \n",
    "    # Test on test set\n",
    "    test_pred = svc.predict(test_X)\n",
    "    test_conf = confusion_matrix(test_Y, test_pred)\n",
    "    print('======= Test result on test set ========')\n",
    "    if verbose:\n",
    "        print_conf_paras(test_conf)\n",
    "    else:\n",
    "        print_conf_paras_simple(test_conf)\n",
    "    \n",
    "    print('================= Done =================')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Preprocess: No preprocess\n",
    "[Back to abstraction](#Abstraction)<br>\n",
    "The code cannot run normally due to encoding issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv('data/feature.csv')\n",
    "# raw_label = pd.read_csv('data/label.csv')\n",
    "# \n",
    "# raw_data.drop(columns=['building_id'], inplace=True)\n",
    "# raw_label = raw_label['damage_grade']\n",
    "# \n",
    "# raw_train_x, raw_test_x, raw_train_y, raw_test_y = train_test_split(raw_data, raw_label, test_size=0.2)\n",
    "# \n",
    "# test_linear_svm_with(raw_train_x, raw_train_y, raw_test_x, raw_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Preprocess: Preprocess 1\n",
    "[Back to abstraction](#Abstraction)<br>\n",
    "- Drop less relevent data\n",
    "- One hot encode catagorical data\n",
    "- Normalize numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6637759017651573\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.23035216872264225\n",
      "  False Positive Rate for 0 \t: 0.01530449738820232\n",
      "  False Negative Rate for 0 \t: 0.7696478312773577\n",
      "  Precision & Recall for  0 \t: 0.6163162097418152 0.23035216872264225\n",
      "  F1 Score for 0            \t: 0.3353609964515895\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.8347999055999461\n",
      "  False Positive Rate for 1 \t: 0.555935259806759\n",
      "  False Negative Rate for 1 \t: 0.16520009440005395\n",
      "  Precision & Recall for  1 \t: 0.664782833401572 0.8347999055999461\n",
      "  F1 Score for 1            \t: 0.7401534201942227\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.49774852291630817\n",
      "  False Positive Rate for 2 \t: 0.12447026263441635\n",
      "  False Negative Rate for 2 \t: 0.5022514770836919\n",
      "  Precision & Recall for  2 \t: 0.6677504376767541 0.49774852291630817\n",
      "  F1 Score for 2            \t: 0.5703510775525631\n",
      "\n",
      "Micro F1 Score          \t: 0.6443235859462847\n",
      "Macro F1 Score          \t: 0.5486218313994584\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.6642236334682757\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.22729083665338645\n",
      "  False Positive Rate for 0 \t: 0.016326617269272415\n",
      "  False Negative Rate for 0 \t: 0.7727091633466135\n",
      "  Precision & Recall for  0 \t: 0.5973821989528796 0.22729083665338645\n",
      "  F1 Score for 0            \t: 0.3292929292929293\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.8366030727671788\n",
      "  False Positive Rate for 1 \t: 0.5556740424775616\n",
      "  False Negative Rate for 1 \t: 0.1633969272328212\n",
      "  Precision & Recall for  1 \t: 0.664556622498793 0.8366030727671788\n",
      "  F1 Score for 1            \t: 0.7407208096028223\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.49771245567882877\n",
      "  False Positive Rate for 2 \t: 0.12201530243972859\n",
      "  False Negative Rate for 2 \t: 0.5022875443211712\n",
      "  Precision & Recall for  2 \t: 0.6731379070307062 0.49771245567882877\n",
      "  F1 Score for 2            \t: 0.5722834127897418\n",
      "\n",
      "Micro F1 Score          \t: 0.6445855804278412\n",
      "Macro F1 Score          \t: 0.5474323838951645\n",
      "================= Done =================\n"
     ]
    }
   ],
   "source": [
    "lsvm1 = test_linear_svm_with(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Preprocess: Preprocess 2\n",
    "[Back to abstraction](#Abstraction)<br>\n",
    "- Drop less relevent data\n",
    "- One hot encode catagorical data\n",
    "- Normalize numerical data\n",
    "- Oversampling train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6530264207770023\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.8156754661002663\n",
      "  False Positive Rate for 0 \t: 0.16683102390344223\n",
      "  False Negative Rate for 0 \t: 0.18432453389973366\n",
      "  Precision & Recall for  0 \t: 0.709691849635529 0.8156754661002663\n",
      "  F1 Score for 0            \t: 0.7590017489784553\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.41133980647988944\n",
      "  False Positive Rate for 1 \t: 0.1729122416641381\n",
      "  False Negative Rate for 1 \t: 0.5886601935201106\n",
      "  Precision & Recall for  1 \t: 0.5432636113677601 0.41133980647988944\n",
      "  F1 Score for 1            \t: 0.46818593897648186\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.7320639897508513\n",
      "  False Positive Rate for 2 \t: 0.18071710326691615\n",
      "  False Negative Rate for 2 \t: 0.2679360102491487\n",
      "  Precision & Recall for  2 \t: 0.6694697734647788 0.7320639897508513\n",
      "  F1 Score for 2            \t: 0.6993691143847557\n",
      "\n",
      "Micro F1 Score          \t: 0.6421856007798976\n",
      "Macro F1 Score          \t: 0.6421856007798977\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.5568388941117783\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.8079681274900399\n",
      "  False Positive Rate for 0 \t: 0.19379631005711132\n",
      "  False Negative Rate for 0 \t: 0.19203187250996015\n",
      "  Precision & Recall for  0 \t: 0.30764563106796117 0.8079681274900399\n",
      "  F1 Score for 0            \t: 0.4456163480553724\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.413270302211717\n",
      "  False Positive Rate for 1 \t: 0.18999377943659468\n",
      "  False Negative Rate for 1 \t: 0.586729697788283\n",
      "  Precision & Recall for  1 \t: 0.7410838631547079 0.413270302211717\n",
      "  F1 Score for 1            \t: 0.5306308259267288\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.727896602996683\n",
      "  False Positive Rate for 2 \t: 0.2798902843943987\n",
      "  False Negative Rate for 2 \t: 0.2721033970033169\n",
      "  Precision & Recall for  2 \t: 0.5676567656765676 0.727896602996683\n",
      "  F1 Score for 2            \t: 0.637867094316929\n",
      "\n",
      "Micro F1 Score          \t: 0.558419254969856\n",
      "Macro F1 Score          \t: 0.5380380894330101\n",
      "================= Done =================\n"
     ]
    }
   ],
   "source": [
    "lsvm2 = test_linear_svm_with(train_x_over, train_y_over, test_x_over, test_y_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Preprocess: Preprocess 3\n",
    "[Back to abstraction](#Abstraction)<br>\n",
    "- Drop geo_level_2_id and geo_level_3_id\n",
    "- One hot encode catagorical data\n",
    "- Normalize numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Preprocess_keep_features_except_geo_2_3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6667881811204912\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.25326070661136374\n",
      "  False Positive Rate for 0 \t: 0.017111567419575632\n",
      "  False Negative Rate for 0 \t: 0.7467392933886362\n",
      "  Precision & Recall for  0 \t: 0.6111178102013747 0.25326070661136374\n",
      "  F1 Score for 0            \t: 0.35811192764273597\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.8338214255659345\n",
      "  False Positive Rate for 1 \t: 0.5478416062465142\n",
      "  False Negative Rate for 1 \t: 0.16617857443406547\n",
      "  Precision & Recall for  1 \t: 0.6685897825192143 0.8338214255659345\n",
      "  F1 Score for 1            \t: 0.7421197107408615\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.5005959304412757\n",
      "  False Positive Rate for 2 \t: 0.12337133843749325\n",
      "  False Negative Rate for 2 \t: 0.4994040695587243\n",
      "  Precision & Recall for  2 \t: 0.6705327947682247 0.5005959304412757\n",
      "  F1 Score for 2            \t: 0.5732350015210188\n",
      "\n",
      "Micro F1 Score          \t: 0.6488477325514083\n",
      "Macro F1 Score          \t: 0.5578222133015388\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.6645689837109802\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.25757872090749073\n",
      "  False Positive Rate for 0 \t: 0.017252382573179032\n",
      "  False Negative Rate for 0 \t: 0.7424212790925093\n",
      "  Precision & Recall for  0 \t: 0.618890977443609 0.25757872090749073\n",
      "  F1 Score for 0            \t: 0.36376191133821295\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.8352985150701688\n",
      "  False Positive Rate for 1 \t: 0.5501057641459545\n",
      "  False Negative Rate for 1 \t: 0.1647014849298311\n",
      "  Precision & Recall for  1 \t: 0.6632132739781464 0.8352985150701688\n",
      "  F1 Score for 1            \t: 0.7393749812013114\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.4971272541100176\n",
      "  False Positive Rate for 2 \t: 0.12127265358114758\n",
      "  False Negative Rate for 2 \t: 0.5028727458899823\n",
      "  Precision & Recall for  2 \t: 0.6759746287128713 0.4971272541100176\n",
      "  F1 Score for 2            \t: 0.5729176910217326\n",
      "\n",
      "Micro F1 Score          \t: 0.6463863138642143\n",
      "Macro F1 Score          \t: 0.5586848611870857\n",
      "================= Done =================\n"
     ]
    }
   ],
   "source": [
    "lsvm3 = test_linear_svm_with(train_x_keep, train_y_keep, test_x_keep, test_y_keep, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Preprocess: Preprocess 4\n",
    "[Back to abstraction](#Abstraction)<br>\n",
    "- drop geo_level_3_id only\n",
    "- One hot encode catagorical data\n",
    "- Normalize numerical data\n",
    "\n",
    "### Failed to run due to Memory Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean memory for next test, which will take lots of memory\n",
    "# del train_x, train_y, test_x, test_y\n",
    "# del train_x_over, train_y_over, test_x_over, test_y_over\n",
    "# del train_x_keep, train_y_keep, test_x_keep, test_y_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run Preprocess_keep_features_except_geo_3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsvm4 = test_linear_svm_with(train_x_keep12, train_y_keep12, test_x_keep12, test_y_keep12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean memory\n",
    "# del train_x_keep12, train_y_keep12, test_x_keep12, test_y_keep12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Hyperparameter: max_iter\n",
    "[Back to abstraction](#Abstraction)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_iter = 10\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6650038372985418\n",
      "Micro F1 Score          \t: 0.6463600586133069\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.662017229139886\n",
      "Micro F1 Score          \t: 0.643059238487166\n",
      "================= Done =================\n",
      "\n",
      "Max_iter = 100\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6650038372985418\n",
      "Micro F1 Score          \t: 0.6463600586133069\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.662017229139886\n",
      "Micro F1 Score          \t: 0.643059238487166\n",
      "================= Done =================\n",
      "\n",
      "Max_iter = 1000\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6650038372985418\n",
      "Micro F1 Score          \t: 0.6463600586133069\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.662017229139886\n",
      "Micro F1 Score          \t: 0.643059238487166\n",
      "================= Done =================\n",
      "\n",
      "Max_iter = 5000\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6650038372985418\n",
      "Micro F1 Score          \t: 0.6463600586133069\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.662017229139886\n",
      "Micro F1 Score          \t: 0.643059238487166\n",
      "================= Done =================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for max_iter in [10, 100, 1000, 5000]:\n",
    "    print('Max_iter =', max_iter)\n",
    "    test_linear_svm_with(train_x, train_y, test_x, test_y, max_iter=max_iter, verbose=False)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Hyperparameter: C: punishment on wrong resoposes\n",
    "[Back to abstraction](#Abstraction)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.0001\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6507338833461244\n",
      "Micro F1 Score          \t: 0.615520964395088\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.6508700907503693\n",
      "Micro F1 Score          \t: 0.6149150584307574\n",
      "================= Done =================\n",
      "\n",
      "C = 0.001\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6626295088257866\n",
      "Micro F1 Score          \t: 0.6419265774910258\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.6597148941885229\n",
      "Micro F1 Score          \t: 0.6386266930609307\n",
      "================= Done =================\n",
      "\n",
      "C = 0.01\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6647448196469685\n",
      "Micro F1 Score          \t: 0.6458628208710776\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.661767809520155\n",
      "Micro F1 Score          \t: 0.6425117620569234\n",
      "================= Done =================\n",
      "\n",
      "C = 0.1\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.66504221028396\n",
      "Micro F1 Score          \t: 0.6463751456045157\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.6620556013890754\n",
      "Micro F1 Score          \t: 0.6430567831434513\n",
      "================= Done =================\n",
      "\n",
      "C = 1\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6650038372985418\n",
      "Micro F1 Score          \t: 0.6463600586133069\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.662017229139886\n",
      "Micro F1 Score          \t: 0.643059238487166\n",
      "================= Done =================\n",
      "\n",
      "C = 10\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6650134305448964\n",
      "Micro F1 Score          \t: 0.6463792830882056\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.662017229139886\n",
      "Micro F1 Score          \t: 0.6430574481817127\n",
      "================= Done =================\n",
      "\n",
      "C = 100\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6650134305448964\n",
      "Micro F1 Score          \t: 0.6463792830882056\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.6619788568906967\n",
      "Micro F1 Score          \t: 0.6430270253949907\n",
      "================= Done =================\n",
      "\n",
      "C = 1000\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.665023023791251\n",
      "Micro F1 Score          \t: 0.64639024698423\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.662017229139886\n",
      "Micro F1 Score          \t: 0.6430574481817127\n",
      "================= Done =================\n",
      "\n",
      "C = 10000\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6650182271680737\n",
      "Micro F1 Score          \t: 0.6463859902037419\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.662017229139886\n",
      "Micro F1 Score          \t: 0.6430574481817127\n",
      "================= Done =================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lgC in range(-4, 5):\n",
    "    print('C =', 10**lgC)\n",
    "    test_linear_svm_with(train_x, train_y, test_x, test_y, verbose=False, C=10**lgC)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Hyperparameter: class_weight\n",
    "[Back to abstraction](#Abstraction)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6426132003069839\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.61587019776101\n",
      "  False Positive Rate for 0 \t: 0.08175215060333789\n",
      "  False Negative Rate for 0 \t: 0.38412980223899\n",
      "  Precision & Recall for  0 \t: 0.4480160723254646 0.61587019776101\n",
      "  F1 Score for 0            \t: 0.5187015845984507\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.675204580578146\n",
      "  False Positive Rate for 1 \t: 0.3751318462922047\n",
      "  False Negative Rate for 1 \t: 0.324795419421854\n",
      "  Precision & Recall for  1 \t: 0.7029453138737471 0.675204580578146\n",
      "  F1 Score for 1            \t: 0.688795751077953\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.5950852557673019\n",
      "  False Positive Rate for 2 \t: 0.18267358857884491\n",
      "  False Negative Rate for 2 \t: 0.4049147442326981\n",
      "  Precision & Recall for  2 \t: 0.6211078874166243 0.5950852557673019\n",
      "  F1 Score for 2            \t: 0.6078181711743356\n",
      "\n",
      "Micro F1 Score          \t: 0.6451444429660078\n",
      "Macro F1 Score          \t: 0.6051051689502464\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.6369793365438116\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.5892304518258716\n",
      "  False Positive Rate for 0 \t: 0.0821593264796717\n",
      "  False Negative Rate for 0 \t: 0.4107695481741283\n",
      "  Precision & Recall for  0 \t: 0.42373887240356084 0.5892304518258716\n",
      "  F1 Score for 0            \t: 0.4929662552860965\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.6745627554781211\n",
      "  False Positive Rate for 1 \t: 0.388641975308642\n",
      "  False Negative Rate for 1 \t: 0.325437244521879\n",
      "  Precision & Recall for  1 \t: 0.6993053143452588 0.6745627554781211\n",
      "  F1 Score for 1            \t: 0.6867112354185142\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.5858962588937342\n",
      "  False Positive Rate for 2 \t: 0.18389876920416223\n",
      "  False Negative Rate for 2 \t: 0.4141037411062658\n",
      "  Precision & Recall for  2 \t: 0.6154541618950033 0.5858962588937342\n",
      "  F1 Score for 2            \t: 0.6003115905817337\n",
      "\n",
      "Micro F1 Score          \t: 0.6398039441363584\n",
      "Macro F1 Score          \t: 0.5933296937621148\n",
      "================= Done =================\n"
     ]
    }
   ],
   "source": [
    "# the default value of class_weight, which all class has uniform weight, is tested in Preprocess 1\n",
    "\n",
    "lsvm5 = test_linear_svm_with(train_x, train_y, test_x, test_y, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Trick Test: RBF\n",
    "[Back to abstraction](#Abstraction)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up RBF SVM\n",
    "rbf_svc = SVC(cache_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  8 03:19:33 2020\n",
      "Wed Apr  8 07:01:18 2020\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "rbf_svc.fit(train_x, train_y)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  8 07:01:18 2020\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6813986953184957\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.40453865336658357\n",
      "  False Positive Rate for 0 \t: 0.026036193812025685\n",
      "  False Negative Rate for 0 \t: 0.5954613466334164\n",
      "  Precision & Recall for  0 \t: 0.6231082430667588 0.40453865336658357\n",
      "  F1 Score for 0            \t: 0.49057973205915256\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.822725471515172\n",
      "  False Positive Rate for 1 \t: 0.49831428793964816\n",
      "  False Negative Rate for 1 \t: 0.17727452848482805\n",
      "  Precision & Recall for  1 \t: 0.6854234859446778 0.822725471515172\n",
      "  F1 Score for 1            \t: 0.7478244875906702\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.5208312447187889\n",
      "  False Positive Rate for 2 \t: 0.12066466171920638\n",
      "  False Negative Rate for 2 \t: 0.47916875528121106\n",
      "  Precision & Recall for  2 \t: 0.6848974518334369 0.5208312447187889\n",
      "  F1 Score for 2            \t: 0.5917019199479336\n",
      "\n",
      "Micro F1 Score          \t: 0.670796938718233\n",
      "Macro F1 Score          \t: 0.6100353798659188\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.6763876364613112\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.3841150965707529\n",
      "  False Positive Rate for 0 \t: 0.028737220226581928\n",
      "  False Negative Rate for 0 \t: 0.6158849034292472\n",
      "  Precision & Recall for  0 \t: 0.5904271432899122 0.3841150965707529\n",
      "  F1 Score for 0            \t: 0.4654328358208955\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.8215297450424929\n",
      "  False Positive Rate for 1 \t: 0.5080332903110952\n",
      "  False Negative Rate for 1 \t: 0.17847025495750707\n",
      "  Precision & Recall for  1 \t: 0.6809224318658281 0.8215297450424929\n",
      "  F1 Score for 1            \t: 0.7446467054885598\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.5142282265018684\n",
      "  False Positive Rate for 2 \t: 0.11806715429361285\n",
      "  False Negative Rate for 2 \t: 0.48577177349813166\n",
      "  Precision & Recall for  2 \t: 0.685703334610962 0.5142282265018684\n",
      "  F1 Score for 2            \t: 0.5877135348226019\n",
      "\n",
      "Micro F1 Score          \t: 0.665089834391918\n",
      "Macro F1 Score          \t: 0.5992643587106857\n",
      "================= Done =================\n",
      "Wed Apr  8 08:06:46 2020\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "test_svm(rbf_svc, train_x, train_y, test_x, test_y)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Trick Test: 3 Degree Polynomial\n",
    "[Back to abstraction](#Abstraction)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Polynomial SVM\n",
    "poly_svc = SVC(kernel='poly', cache_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 11 01:55:52 2020\n",
      "Sat Apr 11 06:26:17 2020\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "poly_svc.fit(train_x, train_y)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 11 06:26:17 2020\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.6820606293169609\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.41130430475058205\n",
      "  False Positive Rate for 0 \t: 0.02578959387762689\n",
      "  False Negative Rate for 0 \t: 0.5886956952494179\n",
      "  Precision & Recall for  0 \t: 0.6309749981001596 0.41130430475058205\n",
      "  F1 Score for 0            \t: 0.49799076350986626\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.8214614222664788\n",
      "  False Positive Rate for 1 \t: 0.49465986507962967\n",
      "  False Negative Rate for 1 \t: 0.17853857773352125\n",
      "  Precision & Recall for  1 \t: 0.6862315213636652 0.8214614222664788\n",
      "  F1 Score for 1            \t: 0.7477818662282892\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.5236846629986245\n",
      "  False Positive Rate for 2 \t: 0.1219932510383018\n",
      "  False Negative Rate for 2 \t: 0.4763153370013755\n",
      "  Precision & Recall for  2 \t: 0.6835677414528316 0.5236846629986245\n",
      "  F1 Score for 2            \t: 0.5930391043323057\n",
      "\n",
      "Micro F1 Score          \t: 0.6717921318229684\n",
      "Macro F1 Score          \t: 0.6129372446901536\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.6749294909921145\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.4024711363176018\n",
      "  False Positive Rate for 0 \t: 0.02867497456765005\n",
      "  False Negative Rate for 0 \t: 0.5975288636823982\n",
      "  Precision & Recall for  0 \t: 0.5949101796407186 0.4024711363176018\n",
      "  F1 Score for 0            \t: 0.48012564938987556\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.8126218159822569\n",
      "  False Positive Rate for 1 \t: 0.5001117917989536\n",
      "  False Negative Rate for 1 \t: 0.18737818401774312\n",
      "  Precision & Recall for  1 \t: 0.6837640671831703 0.8126218159822569\n",
      "  F1 Score for 1            \t: 0.7426448006879185\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.5169861127051533\n",
      "  False Positive Rate for 2 \t: 0.12699236201181727\n",
      "  False Negative Rate for 2 \t: 0.4830138872948468\n",
      "  Precision & Recall for  2 \t: 0.6715616846813268 0.5169861127051533\n",
      "  F1 Score for 2            \t: 0.5842223014817937\n",
      "\n",
      "Micro F1 Score          \t: 0.6648119210209057\n",
      "Macro F1 Score          \t: 0.6023309171865292\n",
      "================= Done =================\n",
      "Sat Apr 11 07:21:38 2020\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "test_svm(poly_svc, train_x, train_y, test_x, test_y)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Trick Test: Sigmoid\n",
    "[Back to abstraction](#Abstraction)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_svc = SVC(kernel='sigmoid', cache_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 15 12:38:15 2020\n",
      "Wed Apr 15 15:26:52 2020\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "sig_svc.fit(train_x, train_y)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 15 15:26:52 2020\n",
      "======= Test result on train set =======\n",
      "Classification Accuracy\t: 0.5457453952417498\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.37790871866573456\n",
      "  False Positive Rate for 0 \t: 0.09391681789720568\n",
      "  False Negative Rate for 0 \t: 0.6220912813342655\n",
      "  Precision & Recall for  0 \t: 0.2995211144971702 0.37790871866573456\n",
      "  F1 Score for 0            \t: 0.33417967456339837\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.6292453307688414\n",
      "  False Positive Rate for 1 \t: 0.5129756054170651\n",
      "  False Negative Rate for 1 \t: 0.3707546692311586\n",
      "  Precision & Recall for  1 \t: 0.6178516996885561 0.6292453307688414\n",
      "  F1 Score for 1            \t: 0.623496468424792\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.4522399588053553\n",
      "  False Positive Rate for 2 \t: 0.2227642745799896\n",
      "  False Negative Rate for 2 \t: 0.5477600411946447\n",
      "  Precision & Recall for  2 \t: 0.505993438425222 0.4522399588053553\n",
      "  F1 Score for 2            \t: 0.4776090092675816\n",
      "\n",
      "Micro F1 Score          \t: 0.5467833920699035\n",
      "Macro F1 Score          \t: 0.4784283840852573\n",
      "======= Test result on test set ========\n",
      "Classification Accuracy\t: 0.5448475662400951\n",
      "\n",
      "  True Positive Rate for  0 \t: 0.37092977638289526\n",
      "  False Positive Rate for 0 \t: 0.09395402249962784\n",
      "  False Negative Rate for 0 \t: 0.6290702236171047\n",
      "  Precision & Recall for  0 \t: 0.2997305436677762 0.37092977638289526\n",
      "  F1 Score for 0            \t: 0.3315508021390374\n",
      "\n",
      "  True Positive Rate for  1 \t: 0.626442776861729\n",
      "  False Positive Rate for 1 \t: 0.5130333868951973\n",
      "  False Negative Rate for 1 \t: 0.373557223138271\n",
      "  Precision & Recall for  1 \t: 0.6182663566921288 0.626442776861729\n",
      "  F1 Score for 1            \t: 0.6223277115683554\n",
      "\n",
      "  True Positive Rate for  2 \t: 0.45596902808274586\n",
      "  False Positive Rate for 2 \t: 0.2243573172483125\n",
      "  False Negative Rate for 2 \t: 0.5440309719172541\n",
      "  Precision & Recall for  2 \t: 0.5025474461851993 0.45596902808274586\n",
      "  F1 Score for 2            \t: 0.4781265147842947\n",
      "\n",
      "Micro F1 Score          \t: 0.5460067162724935\n",
      "Macro F1 Score          \t: 0.4773350094972291\n",
      "================= Done =================\n",
      "Wed Apr 15 16:13:15 2020\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "test_svm(sig_svc, train_x, train_y, test_x, test_y)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on DrivenData Competition Dataset \n",
    "[Back to abstraction](#Abstraction)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 11 19:44:57 2020\n",
      "Sat Apr 11 20:11:51 2020\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "compit_pred = rbf_svc.predict(test_values)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "compit_result = np.concatenate([[test_building_id], [compit_pred]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86868, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compit_result = np.transpose(compit_result)\n",
    "compit_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"compit_answer.csv\", compit_result, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Optimal Model to Avoid Training Again\n",
    "[Back to abstraction](#Abstraction)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rbf_svm_sklearn0.22.2.post1', 'wb') as rbf_file:\n",
    "    pickle.dump(rbf_svc, rbf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
