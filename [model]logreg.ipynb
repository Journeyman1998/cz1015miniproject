{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "[Logistic Regression](#Logistic-Regression)<br>\n",
    "[Oversampling vs No Oversampling](#Oversampling-vs-No-Oversampling)<br>\n",
    "[More features vs less features](#More-features-vs-less-features)<br>\n",
    "[Increase max_iter](#Increase-max_iter)<br>\n",
    "[Model optimization by hyperparameter selection](#Model-optimization-by-hyperparameter-selection)<br>\n",
    "[Competition outcome](#Competition-outcome)<br>\n",
    "[Final Conclusion](#Final-Conclusion)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "[Back to top](#Contents)<br>\n",
    "\n",
    "Logistic Regression is a Linear Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable.\n",
    "\n",
    "#### Note:\n",
    "I will use the term test data and validation data interchangeably. Both refers to the same data that will be used to evaluate models' performance internally. The ACTUAL test data from the competition will be refered to as competition data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "import time \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement logistic regression, display results of the model\n",
    "def implement_logreg(X_train,y_train,X_test,y_test,Max_iter=None):\n",
    "    \n",
    "    start = time.time()\n",
    "    if Max_iter == None:\n",
    "        logreg = LogisticRegression()\n",
    "    else:\n",
    "        logreg = LogisticRegression(max_iter=Max_iter)        \n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "    #print the results: time, accuracy, classification report, confusion matrix, f1-micro\n",
    "    print(\"Time taken to run the model: \",time.time()-start)\n",
    "    print(\"Model accuracy on train data: {:.5f}%\".format(logreg.score(X_train, y_train)*100))\n",
    "    print(\"Model accuracy on test data: {:.5f}%\".format(logreg.score(X_test, y_test)*100))\n",
    "    print_report(logreg,X_train,y_train,X_test,y_test)\n",
    "    return logreg\n",
    "\n",
    "#implement random search, display results of the model with the best hyperparameter found by random search\n",
    "def run_random_search(X_train,y_train,X_test,y_test,C,Max_iter):\n",
    "    \n",
    "    start = time.time()\n",
    "    hyperparameters = dict(C=C)\n",
    "    logistic = LogisticRegression(max_iter=Max_iter)\n",
    "    \n",
    "    #obtain logistic regression model with the best hyperparameter C found by random search\n",
    "    clf = RandomizedSearchCV(logistic, hyperparameters, random_state=1, n_iter=300,\\\n",
    "                             cv=10, verbose=0, n_jobs=-1, scoring = 'f1_micro')    \n",
    "    random_search = clf.fit(X_train,y_train)\n",
    "    \n",
    "    #print the results: time, best C value, accuracy, classification report, confusion matrix, f1-micro\n",
    "    print(\"Time taken to run the model: \",time.time()-start)\n",
    "    print('Best C:', random_search.best_estimator_.get_params()['C'])\n",
    "    print(\"Model accuracy on train data: {:.2f}%\".format(random_search.score(X_train, y_train)*100))\n",
    "    print(\"Model accuracy on test data: {:.2f}%\".format(random_search.score(X_test, y_test)*100))\n",
    "    print_report(random_search,X_train,y_train,X_test,y_test)\n",
    "    return random_search\n",
    "\n",
    "#print the results of the model: classification report, confusion matrix, f1-micro\n",
    "def print_report(model,X_train,y_train,X_test,y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print(\"\\n\\n=============   classification_report on train data   =============\\n\")\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "    print(\"Confusion matrix\\n\")\n",
    "    print(metrics.confusion_matrix(y_train, y_train_pred))\n",
    "    print()\n",
    "    print(\"F1-Micro: \",f1_score(y_train, y_train_pred, average='micro'))\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(\"\\n\\n=============   classification_report on test data   =============\\n\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"Confusion matrix\\n\")\n",
    "    print(metrics.confusion_matrix(y_test, y_test_pred))\n",
    "    print()\n",
    "    print(\"F1-Micro: \",f1_score(y_test, y_test_pred, average='micro'))\n",
    "\n",
    "#store predicted result into csv file\n",
    "def save_result_to_csv(test_pred, file_name):\n",
    "    \n",
    "    #get a list of the predicted damage grade\n",
    "    pred = []\n",
    "    for i in range(test_pred.shape[0]):\n",
    "        if test_pred[i][0] >= test_pred[i][1] and test_pred[i][0] >= test_pred[i][2]:\n",
    "            pred.append(1)\n",
    "        elif test_pred[i][1] >= test_pred[i][0] and test_pred[i][1] >= test_pred[i][2]:\n",
    "            pred.append(2)\n",
    "        else:\n",
    "            pred.append(3)\n",
    "    \n",
    "    #create a csv file with the building ids and the predicted damage grades\n",
    "    new_col = pd.DataFrame(pred,columns=['damage_grade'])\n",
    "    df = pd.read_csv(\"data/submission_format.csv\")\n",
    "    df[\"damage_grade\"] = new_col\n",
    "    df.to_csv(\"{}.csv\".format(file_name), index=False) \n",
    "\n",
    "#save the final model as a pickle file. \n",
    "def save_model_as_pickle(model, filename):\n",
    "    pickle.dump(model,open(filename,\"wb\"))\n",
    "\n",
    "#load the model stored in a pickle file\n",
    "def load_pickle_model(file_name):\n",
    "    infile = open(file_name,'rb')\n",
    "    model = pickle.load(infile)\n",
    "    infile.close()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling vs No Oversampling\n",
    "[Back to top](#Contents)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No oversampling, all less important features removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#get preprocessed train, test and competition data, all less important features removed\n",
    "%run ./Preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run the model:  6.206761598587036\n",
      "Model accuracy on train data: 66.67978%\n",
      "Model accuracy on test data: 66.66795%\n",
      "\n",
      "\n",
      "=============   classification_report on train data   =============\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.32      0.42     20072\n",
      "           2       0.67      0.81      0.74    118670\n",
      "           3       0.66      0.52      0.58     69738\n",
      "\n",
      "    accuracy                           0.67    208480\n",
      "   macro avg       0.64      0.55      0.58    208480\n",
      "weighted avg       0.66      0.67      0.65    208480\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 6445 13296   331]\n",
      " [ 4178 96473 18019]\n",
      " [  192 33450 36096]]\n",
      "\n",
      "F1-Micro:  0.6667977743668457\n",
      "\n",
      "\n",
      "=============   classification_report on test data   =============\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.32      0.42      5052\n",
      "           2       0.67      0.82      0.74     29589\n",
      "           3       0.67      0.51      0.58     17480\n",
      "\n",
      "    accuracy                           0.67     52121\n",
      "   macro avg       0.65      0.55      0.58     52121\n",
      "weighted avg       0.66      0.67      0.65     52121\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 1635  3321    96]\n",
      " [ 1006 24181  4402]\n",
      " [   52  8496  8932]]\n",
      "\n",
      "F1-Micro:  0.6666794574163964\n"
     ]
    }
   ],
   "source": [
    "# logistic reg without oversampling, all less important features removed\n",
    "logreg = implement_logreg(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling, all unimportant features removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run the model:  11.505195140838623\n",
      "Model accuracy on train data: 65.25659%\n",
      "Model accuracy on test data: 58.12053%\n",
      "\n",
      "\n",
      "=============   classification_report on train data   =============\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.77      0.75    118670\n",
      "           2       0.53      0.46      0.49    118670\n",
      "           3       0.67      0.73      0.70    118670\n",
      "\n",
      "    accuracy                           0.65    356010\n",
      "   macro avg       0.65      0.65      0.65    356010\n",
      "weighted avg       0.65      0.65      0.65    356010\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[91251 23213  4206]\n",
      " [26358 54926 37386]\n",
      " [ 6760 25767 86143]]\n",
      "\n",
      "F1-Micro:  0.6525659391590124\n",
      "\n",
      "\n",
      "=============   classification_report on test data   =============\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.77      0.47      5052\n",
      "           2       0.74      0.47      0.57     29589\n",
      "           3       0.57      0.72      0.64     17480\n",
      "\n",
      "    accuracy                           0.58     52121\n",
      "   macro avg       0.55      0.65      0.56     52121\n",
      "weighted avg       0.65      0.58      0.58     52121\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 3911   942   199]\n",
      " [ 6563 13794  9232]\n",
      " [ 1004  3888 12588]]\n",
      "\n",
      "F1-Micro:  0.5812052723470387\n"
     ]
    }
   ],
   "source": [
    "# logistic reg with oversampling, all less important features removed\n",
    "logreg_over = implement_logreg(train_x_over, train_y_over, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train data comparision\n",
    "\n",
    "With oversampling:\n",
    "\n",
    "The F1-score of the minority classes(damage grade 1 and 3) improved by 33% and 12% respectively.\n",
    "\n",
    "The F1-score of the majority class(damage grade 2) decreased by 25%.\n",
    "\n",
    "The F1-micro score decreased by 1.4%.\n",
    "\n",
    "##### Validation data comparision\n",
    "\n",
    "With oversampling:\n",
    "\n",
    "The F1-score of the minority classes(damage grade 1 and 3) improved by 5% and 6% respectively.\n",
    "\n",
    "The F1-score of the majority class(damage grade 2) decreased by 17%.\n",
    "\n",
    "The F1-micro score decreased by 8.5%.\n",
    "\n",
    "##### Conclusion:\n",
    "\n",
    "Oversampling should only be used if we  want more accurate prediction on the minority class and ignore the accuracy of prediction on the majority class. \n",
    "\n",
    "Oversampling reduced the model's overall performance, we will therefore not use oversampling from now on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More features vs less features\n",
    "[Back to top](#Contents)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible underfitting issue\n",
    "\n",
    "Model without oversampling:\n",
    "\n",
    "train f1-micro = 0.6668\n",
    "\n",
    "validation f1-micro = 0.6667\n",
    "\n",
    "Both train and validation results were poor, and were very similar, suggested that our model might underfit.\n",
    "\n",
    "\n",
    "Since underfitting could be reduced by adding more features, we will add more features into our model (features previously identified as less important)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No oversampling, keep all features  except for geo_index_level_2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get preprocessed train, test and competition data, keep all features except for geo_index_level_2 and 3\n",
    "%run ./Preprocess_keep_features_except_geo_2_3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run the model:  7.200513601303101\n",
      "Model accuracy on train data: 66.93016%\n",
      "Model accuracy on test data: 67.58312%\n",
      "\n",
      "\n",
      "=============   classification_report on train data   =============\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.36      0.45     20204\n",
      "           2       0.68      0.81      0.74    118318\n",
      "           3       0.67      0.52      0.58     69958\n",
      "\n",
      "    accuracy                           0.67    208480\n",
      "   macro avg       0.65      0.56      0.59    208480\n",
      "weighted avg       0.67      0.67      0.66    208480\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 7265 12595   344]\n",
      " [ 4537 95785 17996]\n",
      " [  249 33223 36486]]\n",
      "\n",
      "F1-Micro:  0.6693016116653876\n",
      "\n",
      "\n",
      "=============   classification_report on test data   =============\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.34      0.43      4920\n",
      "           2       0.68      0.82      0.75     29941\n",
      "           3       0.67      0.52      0.59     17260\n",
      "\n",
      "    accuracy                           0.68     52121\n",
      "   macro avg       0.65      0.56      0.59     52121\n",
      "weighted avg       0.67      0.68      0.66     52121\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 1650  3182    88]\n",
      " [ 1098 24526  4317]\n",
      " [   59  8152  9049]]\n",
      "\n",
      "F1-Micro:  0.6758312388480651\n"
     ]
    }
   ],
   "source": [
    "# logistic reg without oversampling, keep all features except for geo_index_level_2 and 3\n",
    "logreg_except_geo_2_3 = implement_logreg(train_x_keep, train_y_keep, test_x_keep, test_y_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome\n",
    "\n",
    "##### Adding categorical features previously identified as less important improved model performance\n",
    "\n",
    "f1-micro increased from 0.667 to 0.669 on train data\n",
    "\n",
    "f1_micro increased from 0.667 to 0.676 on validation data\n",
    "\n",
    "Even though more features were added, and f1-micro scores on both train and validation data improved slightly, the underfitting issue was still not solved. The f1-micro score of the validation data even exceeded that of the train data. Still, keeping more features was able to improve model's performance by increasing learning capacity slightly. We will therefore do further optimization based on this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase max_iter \n",
    "[Back to top](#Contents)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously when we ran the models, we noticed from the warning messages that the solver failed to converge when the default max_iter value of 100 was used.\n",
    "\n",
    "To ensure the solver converges, we increased max_iter from 100 to 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run the model:  26.934953451156616\n",
      "Model accuracy on train data: 66.95414%\n",
      "Model accuracy on test data: 67.57929%\n",
      "\n",
      "\n",
      "=============   classification_report on train data   =============\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.36      0.45     20204\n",
      "           2       0.68      0.81      0.74    118318\n",
      "           3       0.67      0.52      0.58     69958\n",
      "\n",
      "    accuracy                           0.67    208480\n",
      "   macro avg       0.65      0.56      0.59    208480\n",
      "weighted avg       0.67      0.67      0.66    208480\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 7261 12603   340]\n",
      " [ 4505 95882 17931]\n",
      " [  247 33268 36443]]\n",
      "\n",
      "F1-Micro:  0.6695414428242518\n",
      "\n",
      "\n",
      "=============   classification_report on test data   =============\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.33      0.43      4920\n",
      "           2       0.68      0.82      0.75     29941\n",
      "           3       0.67      0.52      0.59     17260\n",
      "\n",
      "    accuracy                           0.68     52121\n",
      "   macro avg       0.65      0.56      0.59     52121\n",
      "weighted avg       0.67      0.68      0.66     52121\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 1642  3192    86]\n",
      " [ 1087 24540  4314]\n",
      " [   57  8162  9041]]\n",
      "\n",
      "F1-Micro:  0.6757928665988757\n"
     ]
    }
   ],
   "source": [
    "# logistic reg without oversampling, keep all features except for geo_index_2 and 3 ids, max iter increase from 100 to 500\n",
    "logreg_max_iter = implement_logreg(train_x_keep, train_y_keep, test_x_keep, test_y_keep, Max_iter = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome \n",
    "\n",
    "##### When the number of iterations increased\n",
    "\n",
    "The F1-micro on train data increased from 0.6693 to 0.6695\n",
    "\n",
    "The F1-micro on validation data decreased from 0.67583 to 0.67579\n",
    "\n",
    "##### Increased running time\n",
    "\n",
    "The running time increased from 7s to 27s\n",
    "\n",
    "##### Conclusion\n",
    "\n",
    "The solver converged with 500 iterations and obtained parameters that decreased the error on the train data.\n",
    "\n",
    "However, there might be an increased overfitting effect, for which the model fitted even better on the train data, but was unable to generalize on the validation data. We could infer this from the decrease in the f1-micro score on the validation data.\n",
    "\n",
    "Due to this problem, and the significant increase in executional time, we will keep our iteration at 100 for hyperparameter selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model optimization by hyperparameter selection\n",
    "[Back to top](#Contents)<br>\n",
    "\n",
    "We will tune the hyperparameter C using random search.\n",
    "\n",
    "#### Hyperparameter C \n",
    "C is the inverse of the regularization strength(lambda). The lower the value of C, the greater the strength of regularization. The tunning of this parameter is generally used to address the issue of overfitting.\n",
    "\n",
    "#### Random search\n",
    "The random search function tries random C values, evaluates the models' performance using k-fold cross validation and returns the solution that maximise the f1-micro score. \n",
    "\n",
    "#### Cross Validation\n",
    "Cross validation generally give us a better indication of how well the model will perform on unseen data, while train test split may result in overfitting hence unable to generalize on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run the model:  6699.820973157883\n",
      "Best C: 3.2295651548380953\n",
      "Model accuracy on train data: 66.93%\n",
      "Model accuracy on test data: 67.58%\n",
      "\n",
      "\n",
      "=============   classification_report on train data   =============\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.36      0.45     20204\n",
      "           2       0.68      0.81      0.74    118318\n",
      "           3       0.67      0.52      0.59     69958\n",
      "\n",
      "    accuracy                           0.67    208480\n",
      "   macro avg       0.65      0.56      0.59    208480\n",
      "weighted avg       0.67      0.67      0.66    208480\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 7250 12606   348]\n",
      " [ 4516 95751 18051]\n",
      " [  247 33166 36545]]\n",
      "\n",
      "F1-Micro:  0.6693495778971604\n",
      "\n",
      "\n",
      "=============   classification_report on test data   =============\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.33      0.42      4920\n",
      "           2       0.68      0.82      0.75     29941\n",
      "           3       0.67      0.53      0.59     17260\n",
      "\n",
      "    accuracy                           0.68     52121\n",
      "   macro avg       0.65      0.56      0.59     52121\n",
      "weighted avg       0.67      0.68      0.66     52121\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      "[[ 1637  3194    89]\n",
      " [ 1090 24512  4339]\n",
      " [   58  8127  9075]]\n",
      "\n",
      "F1-Micro:  0.6758120527234703\n"
     ]
    }
   ],
   "source": [
    "# random search\n",
    "C = uniform(loc=0, scale=4)\n",
    "random_search = run_random_search(train_x_keep, train_y_keep, test_x_keep, test_y_keep, C, Max_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome \n",
    "\n",
    "##### Negligible change in performance \n",
    "\n",
    "The F1-micro on train data increased from 0.66930 to 0.66935\n",
    "\n",
    "The F1-micro on validation data decreased from to 0.67583 to 0.67581  \n",
    "\n",
    "##### Reason for the negligible change in performance\n",
    "\n",
    "Tunning the regularization parameter (C) is used to address the overfitting issue of the model\n",
    "\n",
    "Our model might suffer from underfitting instead of overfitting. The default C value used before random search assumed there was completely no overfitting, therefore the default C value was already very good.\n",
    "\n",
    "Even with 300 random search iterations, we still could not find any C value that performed better than the default C value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition outcome\n",
    "[Back to top](#Contents)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Currently, the top 3 models with the highest f1-micro score on the validation data are:\n",
    "\n",
    "1. logreg_except_geo_2_3 (no oversampling, increased features)\n",
    "\n",
    "F1-Micro:  0.67583\n",
    "\n",
    "2. logreg_max_iter (no oversampling, increased features, increased max_iter)\n",
    "\n",
    "F1-Micro:  0.67579\n",
    "\n",
    "3. random_search (no oversampling, increased features,  hyperparamter tuning)\n",
    "\n",
    "F1-Micro:  0.67581\n",
    "\n",
    "#### We will predict all the 3 models with the competition test data and submit them for the competition \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save logreg_except_geo_2_3's prediction to csv\n",
    "test_pred = logreg_except_geo_2_3.predict_proba(test_values_keep)\n",
    "save_result_to_csv(test_pred, 'logreg_except_geo_2_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save logreg_max_iter's prediction to csv\n",
    "test_pred = logreg_max_iter.predict_proba(test_values_keep)\n",
    "save_result_to_csv(test_pred, 'logreg_max_iter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save random_search's prediction to csv\n",
    "test_pred = random_search.predict_proba(test_values_keep)\n",
    "save_result_to_csv(test_pred, 'random_search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Competition score:\n",
    "\n",
    "logreg_except_geo_2_3: 0.6711\n",
    "\n",
    "logreg_max_iter: 0.6708\n",
    "\n",
    "random_search: 0.6711"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There wass a tie between logreg_except_geo_2_3 and random_search. Since logreg_except_geo_2_3 had a slightly better f1-micro score on the validation data, it would be the final model for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model in a pickle file \n",
    "save_model_as_pickle(logreg_except_geo_2_3, 'logreg.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Conclusion\n",
    "[Back to top](#Contents)<br>\n",
    "\n",
    "We have tried many different ways to optimize the logistic regression model. Here summarised all our discoveries.\n",
    "\n",
    "1. Random oversampling increased the weight of the minority classes, but reduced the overall performance.\n",
    "\n",
    "2. Adding features previously identified as less important improved models' performance. Firstly, this implied that these features still had some relation with damage grade. Secondly, this showed that adding more features could reduce the issue of underfitting.\n",
    "\n",
    "3. Increasing max_iter might increased the risk of overfitting.\n",
    "\n",
    "4. Optimizing the regularization parameter would not help if overfitting was not a issue.\n",
    "\n",
    "Additionally, logistic regression was a simple machine learning algorithm that could be trained very fast. Therefore it could be used as a quckly implemented baseline model to compare with more complex algorithms.\n",
    "\n",
    "Since our models still lacked learning capacity, we could even one-hot encode geo_index_level_2 and level_3 to train our models. I would be very happy to try this if I can find a better computer in the future, such as some computers at Lee Wee Nam library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
